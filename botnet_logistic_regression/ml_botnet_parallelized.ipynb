{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79ca8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:16.515868Z",
     "start_time": "2023-12-19T21:40:16.510992Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import findspark\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd450eed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:18.205990Z",
     "start_time": "2023-12-19T21:40:18.203230Z"
    }
   },
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b7488",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:20.253408Z",
     "start_time": "2023-12-19T21:40:20.243778Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to read the file and return the features and labels as an RDD\n",
    " Arguments:\n",
    "  filename – name of the spam dataset file\n",
    "    12 columns: 11 features/dimensions (X) + 1 column with labels (Y)\n",
    "         Y -- Train labels (0 if normal traffic, 1 if botnet) \n",
    "    m rows: number of examples (m)\n",
    "\n",
    " Returns:\n",
    "  An RDD containing the data of filename. Each example (row) of the file\n",
    "  corresponds to one RDD record. Each record of the RDD is a tuple (X,y).\n",
    "  “X” is an array containing the 11 features (float number) of an example\n",
    "  “y” is the 12th column of an example (integer 0/1)\n",
    "'''\n",
    "def readFile(filename):\n",
    "    # Read the file into an RDD using textFile\n",
    "    rdd = sc.textFile(filename)\n",
    "\n",
    "    # Process each line to split the features and labels\n",
    "    rdd2 = rdd.map(lambda line: line.split(\",\")) \\\n",
    "              .map(lambda fields: (np.array(fields[:-1], dtype=float), int(fields[-1])))\n",
    "    # We get the rdd2 filled with tuples (X,y)\n",
    "\n",
    "    return rdd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e77f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:22.667011Z",
     "start_time": "2023-12-19T21:40:22.657307Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to normalize the features in X\n",
    " Arguments:\n",
    "  RDD_Xy is an RDD containing data examples. Each record of the RDD is a tuple (X,y).\n",
    "  “X” is an array containing the 11 features (float number) of an example\n",
    "  “y” is the label of the example (integer 0/1)\n",
    "\n",
    " Returns:\n",
    "  An RDD rescaled to N(0,1) in each column (mean=0, standard deviation=1)\n",
    "'''\n",
    "def normalize(RDD_Xy):\n",
    "    # Extract array with features\n",
    "    X = RDD_Xy.map(lambda row: row[0])\n",
    "    dim = (X.count(), len(X.first())) # more efficient that X.take(1)[0]\n",
    "\n",
    "    # Compute mean for each column\n",
    "    sumsCol = X.reduce(lambda x, y: [x[i] + y[i] for i in range(dim[1])])\n",
    "    means = [sumCol / dim[0] for sumCol in sumsCol]\n",
    "\n",
    "    # Compute variance for each column\n",
    "    variances = X.map(lambda row: [(row[i] - means[i]) ** 2 for i in range(dim[1])]) \\\n",
    "                .reduce(lambda x, y: [x[i] + y[i] for i in range(dim[1])])\n",
    "    variances = [variance / dim[0] for variance in variances]\n",
    "\n",
    "    # Normalization function\n",
    "    def normalize_row(row):\n",
    "        return [(row[i] - means[i]) / (variances[i] ** 0.5) for i in range(dim[1])]\n",
    "\n",
    "    # Apply the normalization to the initial RDD\n",
    "    normalized_data = RDD_Xy.map(lambda row: (np.array(normalize_row(row[0]),dtype=float), row[1]))\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cb372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:23.595490Z",
     "start_time": "2023-12-19T21:40:23.573559Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to perform gradient descent and train the logistic regression model\n",
    " Arguments:\n",
    "  RDD_Xy --- RDD containing data examples. Each record of the RDD is a tuple (X,y).\n",
    "  “X” is an array containing the 11 features (float number) of an example\n",
    "  “y” is the label of the example (integer 0/1)\n",
    "  iterations -- number of iterations of the optimization loop\n",
    "  learning_rate -- learning rate of the gradient descent\n",
    "  lambda_reg – regularization rate\n",
    "  \n",
    " Returns:\n",
    "  A list containing the weights “w” and bias “b” at the end of the\n",
    "  training process\n",
    "'''\n",
    "def train(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    \n",
    "    X = RDD_Xy.map(lambda row: row[0])\n",
    "    dim = (X.count(), len(X.first())) # more efficient than X.take(1)\n",
    "\n",
    "    J_values = []  # Initialize list to store cost values\n",
    "\n",
    "    # Initialize weights and bias\n",
    "    ws = []\n",
    "    for i in range(dim[1]+1):\n",
    "        ws.append(rd.uniform(-1,1))\n",
    "    #ws = [0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5]\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        \n",
    "        def compute_predictions(row):\n",
    "            (X_line, y) = (row[0], row[1])\n",
    "            Y_pred = 0\n",
    "            \n",
    "            for i in range(dim[1]):\n",
    "                Y_pred += X_line[i]*ws[i] # x1*w1 + x2*w2 + ...\n",
    "            Y_pred += ws[-1] # + b\n",
    "            \n",
    "            # Pass Y_pred into sigmoidal function to be between 0 and 1\n",
    "            Y_pred = 1/(1+np.exp(-Y_pred))\n",
    "            return (X_line, Y_pred, y)\n",
    "\n",
    "        predictions = RDD_Xy.map(compute_predictions)\n",
    "\n",
    "        # Compute cost function\n",
    "        def compute_cost(row):\n",
    "            (_, Y_pred, y) = row\n",
    "            cost = y * np.log(Y_pred) + (1 - y) * np.log(1 - Y_pred)\n",
    "            return cost\n",
    "\n",
    "        cost_values = predictions.map(compute_cost)\n",
    "        J = cost_values.reduce(lambda x, y: x + y)\n",
    "        J *= -1 / dim[0]\n",
    "        \n",
    "        add_term = 0\n",
    "        for i in range(dim[1]):\n",
    "            add_term += ws[i]**2\n",
    "        add_term *= (lambda_reg/(2*dim[1]))\n",
    "        J += add_term\n",
    "        J_values.append(J)\n",
    "        \n",
    "        def compute_derivatives(row):\n",
    "            (X_line, Y_pred, y) = (row[0], row[1], row[2])\n",
    "\n",
    "            derivatives = []\n",
    "            # Compute weight derivatives\n",
    "            for i in range(dim[1]):\n",
    "                derivatives.append((Y_pred-y)*X_line[i])\n",
    "            derivatives.append(Y_pred-y)\n",
    "            \n",
    "            return derivatives\n",
    "\n",
    "        derivatives = predictions.map(compute_derivatives)\n",
    "\n",
    "        # Sum up derivatives\n",
    "        dWs = derivatives.reduce(lambda x, y: [x[i] + y[i] for i in range(dim[1]+1)])\n",
    "        \n",
    "        # Compute weight derivatives\n",
    "        for i in range(dim[1]):\n",
    "            dWs[i] /= dim[0]\n",
    "            dWs[i] += (lambda_reg/dim[1])*ws[i]\n",
    "            \n",
    "        # Compute bias derivative\n",
    "        dWs[-1] /= dim[0]\n",
    "\n",
    "        # Compute new weights and bias\n",
    "        for i in range(dim[1]+1):\n",
    "            ws[i] -= learning_rate*dWs[i]\n",
    "            \n",
    "    axis = plt.gca()\n",
    "    plt.plot(range(iterations), J_values, color=\"darkcyan\")\n",
    "    plt.title(\"Evolution of cost function per iteration\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"cost\")\n",
    "    axis.xaxis.set_ticks(range(iterations))\n",
    "    axis.yaxis.set_ticks(np.arange(0, J_values[0], 0.1))\n",
    "    \n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1e7b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:26.032099Z",
     "start_time": "2023-12-19T21:40:26.029015Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to compute the Y_pred, the prediction of X\n",
    " Arguments:\n",
    "  X – Example to be predicted\n",
    "  ws -- weights & bias\n",
    "\n",
    " Returns:\n",
    "  Y_pred – a value (0/1) corresponding to the prediction of X\n",
    "'''\n",
    "def predict(X, ws):\n",
    "    # Initialize the prediction\n",
    "    Y_pred = ws[-1]\n",
    "    \n",
    "    # Compute the prediction\n",
    "    for i in range(len(X)):\n",
    "        Y_pred += X[i]*ws[i]\n",
    "    \n",
    "    # Pass the prediction into sigmoidal function to be between 0 and 1\n",
    "    Y_pred = 1/(1+np.exp(-Y_pred))\n",
    "    \n",
    "    # Finish the prediction by choosing 0 or 1\n",
    "    return (Y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b949d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:26.918239Z",
     "start_time": "2023-12-19T21:40:26.910045Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_threshold(X, ws, threshold):\n",
    "    # Initialize the prediction\n",
    "    Y_pred = ws[-1]\n",
    "    \n",
    "    # Compute the prediction\n",
    "    for i in range(len(X)):\n",
    "        Y_pred += X[i]*ws[i]\n",
    "    \n",
    "    # Pass the prediction into sigmoidal function to be between 0 and 1\n",
    "    Y_pred = 1/(1+np.exp(-Y_pred))\n",
    "    \n",
    "    # Finish the prediction by choosing 0 or 1\n",
    "    return (Y_pred >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c20328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:27.891478Z",
     "start_time": "2023-12-19T21:40:27.886668Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to compute the accuracy of the logistic regression model\n",
    " Arguments:\n",
    "  RDD_Xy -- RDD containing examples to be predicted\n",
    "  ws -- weights & bias\n",
    "\n",
    " Returns:\n",
    "  accuracy -- the number of predictions that are correct divided by the number\n",
    "  of records (examples) in RDD_xy.\n",
    "  Predict function can be used for predicting a single example\n",
    "'''\n",
    "def accuracy(RDD_Xy, ws):\n",
    "    # Predict using the given weights\n",
    "    predictions = RDD_Xy.map(lambda row: (predict(row[0], ws), row[1]))\n",
    "\n",
    "    # Count correct predictions and sum up the correct count\n",
    "    correct_count = predictions.map(lambda pred: int(pred[0] == pred[1])).reduce(lambda x, y: x + y)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = correct_count / RDD_Xy.count()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd49a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:28.584535Z",
     "start_time": "2023-12-19T21:40:28.579277Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(RDD_Xy, ws, threshold=0.5):\n",
    "    # Predictions on the data\n",
    "    predictions = RDD_Xy.map(lambda row: (predict_with_threshold(row[0], ws, threshold), row[1]))\n",
    "\n",
    "    # Calculate TP, FP, TN, FN\n",
    "    TP = predictions.flatMap(lambda x: [x[0]] if x[0] == 1 and x[1] == 1 else []).count()\n",
    "    FP = predictions.flatMap(lambda x: [x[0]] if x[0] == 1 and x[1] == 0 else []).count()\n",
    "    TN = predictions.flatMap(lambda x: [x[0]] if x[0] == 0 and x[1] == 0 else []).count()\n",
    "    FN = predictions.flatMap(lambda x: [x[0]] if x[0] == 0 and x[1] == 1 else []).count()\n",
    "\n",
    "    return (TP,FP,TN,FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aca781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:29.529865Z",
     "start_time": "2023-12-19T21:40:29.523481Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_error_metrics(data,ws,threshold):\n",
    "    (TP,FP,TN,FN) = confusion_matrix(data,ws,threshold)\n",
    "    \n",
    "    # Calculate precision\n",
    "    precision = TP/(TP+FP) if (TP+FP) != 0 else 1.0\n",
    "    print(\"Precision:\", precision)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = TP/(TP+FN) if (TP+FN) != 0 else 1.0\n",
    "    print(\"Recall:\", recall)\n",
    "    \n",
    "    # Calculate f1_score\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "    print(\"F1-Score:\", f1_score)\n",
    "    \n",
    "    # Calculate specificity\n",
    "    specificity = TN/(TN+FP)\n",
    "    print(\"Specificity:\", specificity)\n",
    "    \n",
    "    return (precision, accuracy, recall, f1_score, specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade0baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:30.849093Z",
     "start_time": "2023-12-19T21:40:30.845152Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(data, ws):\n",
    "    # Predictions on the data with varying thresholds\n",
    "    thresholds = [i * 0.1 for i in range(11)]  # Thresholds from 0.0 to 1.0\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    for threshold in thresholds:\n",
    "        (precision, accu, recall, f1_score, specificity) = get_error_metrics(data,ws,threshold)\n",
    "        fprs.append(1-specificity)\n",
    "        tprs.append(recall)\n",
    "        precisions.append(precision)\n",
    "    \n",
    "    return (fprs,tprs,precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea7806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:32.361878Z",
     "start_time": "2023-12-19T21:40:32.357859Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_roc_curve(fprs, tprs):\n",
    "    plt.figure()\n",
    "    plt.plot(fprs, tprs, color='darkorange', lw=2, label='ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1ed0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:33.388166Z",
     "start_time": "2023-12-19T21:40:33.383561Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_precision_recall_curve(recalls, precisions):\n",
    "    plt.figure()\n",
    "    plt.plot(recalls, precisions, color='darkorange', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ee0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:35.948222Z",
     "start_time": "2023-12-19T21:40:35.945265Z"
    }
   },
   "outputs": [],
   "source": [
    "# MAIN\n",
    "\n",
    "def main():\n",
    "    #path = \"botnet_reduced_l.csv\"\n",
    "    path = \"botnet_tot_syn_l.csv\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    data = readFile(path)\n",
    "    data = normalize(data)\n",
    "\n",
    "    ws = train(data, 10, 1.5, 0.1)\n",
    "\n",
    "    acc = accuracy(data,ws)\n",
    "    print(\"accuracy: \", acc)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Execution time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fdea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T18:49:21.056805Z",
     "start_time": "2023-12-19T18:46:40.435564Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\", \"Botnet classifier with Spark\")\n",
    "main()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476bf1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T19:44:50.754556Z",
     "start_time": "2023-12-19T19:44:50.738223Z"
    }
   },
   "outputs": [],
   "source": [
    "def main_with_metrics():\n",
    "    #path = \"botnet_reduced_l.csv\"\n",
    "    path = \"botnet_tot_syn_l.csv\"\n",
    "    data = readFile(path)\n",
    "    data = normalize(data)\n",
    "\n",
    "    ws = train(data, 10, 1.5, 0.1)\n",
    "    \n",
    "    (fprs, tprs, precisions) = evaluate(data, ws)\n",
    "    \n",
    "    show_roc_curve(fprs, tprs)\n",
    "    show_precision_recall_curve(tprs, precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca4ad8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T19:55:53.877085Z",
     "start_time": "2023-12-19T19:44:50.760786Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\", \"Botnet classifier with Spark\")    \n",
    "main_with_metrics()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a80bb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T19:44:50.728291Z",
     "start_time": "2023-12-19T19:07:34.013964Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cores = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "execution_times = []\n",
    "\n",
    "for cores in num_cores:\n",
    "    sc = SparkContext(master=f\"local[{cores}]\", appName=\"Botnet PerformanceTest\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Running\n",
    "    main() \n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_times.append(end_time - start_time)\n",
    "    sc.stop()\n",
    "    \n",
    "# Compute speedup\n",
    "base_time = execution_times[0]  # ExecTime with 1 worker\n",
    "speedups = [base_time / time for time in execution_times]\n",
    "\n",
    "# Ploting Performance curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(num_cores, execution_times, marker='o')\n",
    "plt.title(\"Performance curve\")\n",
    "plt.xlabel(\"Number of workers\")\n",
    "plt.ylabel(\"Execution time (seconds)\")\n",
    "\n",
    "# Ploting Speedup curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(num_cores, speedups, marker='o', color='green')\n",
    "plt.title(\"Speedup curve\")\n",
    "plt.xlabel(\"Number of workers\")\n",
    "plt.ylabel(\"Time with one worker/time with n workers\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec725f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6516ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:41.738469Z",
     "start_time": "2023-12-19T21:40:41.734522Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_block_data(data_cv, index):\n",
    "    train_data = data_cv.flatMap(lambda row: [row[1]] if row[0] != index else [])\n",
    "    test_data = data_cv.flatMap(lambda row: [row[1]] if row[0] == index else [])\n",
    "    #train_data = data_cv.filter(lambda x: x[0] != index).values()\n",
    "    #test_data = data_cv.filter(lambda x: x[0] == index).values()\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Preprocesses the data for cross-validation by randomly indexing elements\n",
    "def transform(data):\n",
    "    # Assign a discrete random number following a uniform distribution (0 to 9) to each record\n",
    "    random_assigned_rdd = data.map(lambda x: (rd.randint(0, 10), x))\n",
    "    \n",
    "    return random_assigned_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf20e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T21:40:44.295908Z",
     "start_time": "2023-12-19T21:40:44.292174Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_valid():\n",
    "    #path = \"botnet_reduced_l.csv\"\n",
    "    path = \"botnet_tot_syn_l.csv\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    data = readFile(path)\n",
    "    data = normalize(data)\n",
    "\n",
    "    num_blocks_cv=10\n",
    "\n",
    "    # Shuffle Rows and transform data\n",
    "    data_cv=transform(data)\n",
    "    accuracys = []\n",
    "    avg_acc = 0\n",
    "    for i in range(num_blocks_cv) :\n",
    "        print(\"it : \", i)\n",
    "        tr_data, test_data = get_block_data(data_cv,i)\n",
    "        \n",
    "        ws = train(tr_data, 10, 1.5, 0.1)\n",
    "        \n",
    "        acc = accuracy(test_data, ws)\n",
    "        accuracys.append(acc)\n",
    "        avg_acc+=acc\n",
    "    \n",
    "    avg_acc /= num_blocks_cv\n",
    "    print (\"average acc:\",avg_acc)\n",
    "    print(accuracys)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Execution time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b31ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T22:01:22.200324Z",
     "start_time": "2023-12-19T21:41:02.825467Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\", \"Botnet classifier with Spark\") \n",
    "cross_valid()\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
